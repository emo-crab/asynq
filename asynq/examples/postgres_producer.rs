//! PostgresSQL ç”Ÿäº§è€…ç¤ºä¾‹
//! PostgresSQL Producer example
//!
//! æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ asynq å®¢æˆ·ç«¯å°†ä»»åŠ¡åŠ å…¥ PostgresSQL é˜Ÿåˆ—
//! Demonstrates how to use asynq client to enqueue tasks to PostgresSQL

use asynq::client::Client;
use serde::{Deserialize, Serialize};
#[derive(Serialize, Deserialize)]
struct EmailPayload {
  to: String,
  subject: String,
  body: String,
}

#[derive(Serialize, Deserialize)]
struct ImageResizePayload {
  src_url: String,
  width: u32,
  height: u32,
}
#[cfg(not(feature = "postgres"))]
fn main() {}
#[cfg(feature = "postgres")]
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
  tracing_subscriber::fmt::init();

  // åˆ›å»º PostgresSQL é…ç½® - ä¼˜å…ˆä»ç¯å¢ƒå˜é‡ä¸­è¯»å–ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤çš„æµ‹è¯• PostgresSQL æœåŠ¡å™¨
  // Create PostgresSQL config - first read from environment variable, otherwise use the default test PostgresSQL server
  let database_url = std::env::var("DATABASE_URL")
    .unwrap_or_else(|_| "postgres://postgres:postgres@localhost:5432/asynq".to_string());
  println!("ğŸ”— Using PostgresSQL URL: {database_url}");

  // åˆ›å»º PostgresSQL å®¢æˆ·ç«¯
  // Create PostgresSQL client
  let client = Client::new_with_postgres(&database_url).await?;
  println!("âœ… Connected to PostgresSQL");

  // ç¤ºä¾‹ 1: åˆ›å»ºé‚®ä»¶å‘é€ä»»åŠ¡
  // Example 1: Create email sending task
  let email_payload = EmailPayload {
    to: "user@example.com".to_string(),
    subject: "Welcome!".to_string(),
    body: "Welcome to our service!".to_string(),
  };

  let email_payload_bin = serde_json::to_vec(&email_payload)?;
  let email_task = asynq::task::Task::new("email:send", &email_payload_bin).unwrap();

  // ç«‹å³æ’é˜Ÿå¤„ç†
  // Immediately enqueue for processing
  match client.enqueue(email_task).await {
    Ok(task_info) => {
      println!("ğŸ“§ Email task enqueued: ID = {}", task_info.id);
    }
    Err(e) => {
      println!("âŒ Failed to enqueue email task: {e}");
    }
  }

  // ç¤ºä¾‹ 2: åˆ›å»ºå›¾ç‰‡è°ƒæ•´å¤§å°ä»»åŠ¡
  // Example 2: Create image resize task
  let image_payload = ImageResizePayload {
    src_url: "https://example.com/image.jpg".to_string(),
    width: 800,
    height: 600,
  };

  let image_payload_bin = serde_json::to_vec(&image_payload)?;
  let image_task = asynq::task::Task::new("image:resize", &image_payload_bin)
    .unwrap()
    .with_queue("image_processing")
    .with_max_retry(5)
    .with_timeout(std::time::Duration::from_secs(300)); // 5 åˆ†é’Ÿè¶…æ—¶

  // ç«‹å³æ’é˜Ÿå¤„ç†
  // Immediately enqueue for processing
  match client.enqueue(image_task).await {
    Ok(task_info) => {
      println!("ğŸ–¼ï¸  Image task enqueued: ID = {}", task_info.id);
    }
    Err(e) => {
      println!("âŒ Failed to enqueue image task: {e}");
    }
  }

  // ç¤ºä¾‹ 3: è°ƒåº¦å»¶è¿Ÿä»»åŠ¡
  // Example 3: Schedule delayed task
  let delayed_email_bin = serde_json::to_vec(&email_payload)?;
  let delayed_email = asynq::task::Task::new("email:reminder", &delayed_email_bin).unwrap();

  // 30 ç§’åæ‰§è¡Œ
  // Execute after 30 seconds
  let process_at = std::time::SystemTime::now()
    .checked_add(std::time::Duration::from_secs(30))
    .unwrap();
  match client.schedule(delayed_email, process_at).await {
    Ok(task_info) => {
      println!("â° Delayed email task scheduled: ID = {}", task_info.id);
    }
    Err(e) => {
      println!("âŒ Failed to schedule delayed task: {e}");
    }
  }

  // ç¤ºä¾‹ 4: å”¯ä¸€ä»»åŠ¡ï¼ˆå»é‡ï¼‰
  // Example 4: Unique task (deduplication)
  let unique_payload_bin = serde_json::to_vec(&serde_json::json!({"date": "2023-01-01"}))?;
  let unique_task = asynq::task::Task::new("report:daily", &unique_payload_bin).unwrap();

  // åœ¨ 1 å°æ—¶å†…ä¿æŒå”¯ä¸€æ€§
  // Maintain uniqueness within 1 hour
  match client
    .enqueue_unique(unique_task, std::time::Duration::from_secs(3600))
    .await
  {
    Ok(task_info) => {
      println!("ğŸ”’ Unique task enqueued: ID = {}", task_info.id);
    }
    Err(e) => {
      println!("âŒ Failed to enqueue unique task: {e}");
    }
  }

  // ç¤ºä¾‹ 5: ç»„ä»»åŠ¡ï¼ˆç”¨äºèšåˆï¼‰
  // Example 5: Group task (for aggregation)
  for i in 1..=5 {
    let batch_payload_bin = serde_json::to_vec(&serde_json::json!({"item": i}))?;
    let batch_task = asynq::task::Task::new("batch:process", &batch_payload_bin).unwrap();

    match client.add_to_group(batch_task, "daily_batch").await {
      Ok(task_info) => {
        println!("ğŸ“¦ Batch task {} added to group: ID = {}", i, task_info.id);
      }
      Err(e) => {
        println!("âŒ Failed to add batch task {i} to group: {e}");
      }
    }
  }

  // ç¤ºä¾‹ 6: ä½¿ç”¨å”¯ä¸€ç»„ä»»åŠ¡
  // Example 6: Use unique group task
  let group_payload_bin = serde_json::to_vec(&serde_json::json!({"priority": "high"}))?;
  let group_task = asynq::task::Task::new("group:process", &group_payload_bin).unwrap();

  match client
    .add_to_group_unique(
      group_task,
      "priority_group",
      std::time::Duration::from_secs(3600),
    )
    .await
  {
    Ok(task_info) => {
      println!("ğŸ”’ Unique group task added: ID = {}", task_info.id);
    }
    Err(e) => {
      println!("âŒ Failed to add unique group task: {e}");
    }
  }

  // å…³é—­è¿æ¥
  // Close connection
  client.close().await?;

  println!("\nâœ… All tasks have been enqueued successfully!");

  Ok(())
}
