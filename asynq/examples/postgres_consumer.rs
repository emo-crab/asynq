//! PostgresSQL æ¶ˆè´¹è€…ç¤ºä¾‹
//! PostgresSQL Consumer example
//!
//! æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ ServerBuilder å¤„ç† PostgresSQL é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
//! Demonstrates how to use ServerBuilder to process tasks from PostgresSQL queue

use async_trait::async_trait;
use asynq::components::aggregator::GroupAggregatorFunc;
use asynq::error::{Error, Result};
use asynq::pgdb::PostgresBroker;
use asynq::task::Task;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use std::time::Duration;
/// è‡ªå®šä¹‰èšåˆå™¨ç¤ºä¾‹ - å°†å¤šä¸ªä»»åŠ¡çš„ payload åˆå¹¶
/// Custom aggregator example - combines payloads from multiple tasks
fn aggregate_tasks(group: &str, tasks: Vec<Task>) -> Result<Task> {
  println!(
    "ğŸ“¦ Aggregating {} tasks from group '{}'",
    tasks.len(),
    group
  );

  // åˆå¹¶æ‰€æœ‰ä»»åŠ¡çš„ payload
  // Combine payloads from all tasks
  let mut combined_payload: Vec<serde_json::Value> = Vec::new();
  for (idx, task) in tasks.iter().enumerate() {
    println!(
      "   Task {}: type='{}', payload size={} bytes",
      idx + 1,
      task.get_type(),
      task.get_payload().len()
    );

    if let Ok(payload_str) = serde_json::from_slice(task.get_payload()) {
      combined_payload.push(payload_str);
    }
  }

  println!("   âœ… Created aggregated task with combined payload");
  let data = serde_json::to_vec(&combined_payload)?;
  // åˆ›å»ºèšåˆåçš„ä»»åŠ¡
  // Create the aggregated task
  Task::new("batch:process", &data)
}

#[derive(Serialize, Deserialize)]
struct EmailPayload {
  to: String,
  subject: String,
  body: String,
}

#[derive(Serialize, Deserialize)]
struct ImageResizePayload {
  src_url: String,
  width: u32,
  height: u32,
}

/// ä»»åŠ¡å¤„ç†å™¨
pub struct TaskProcessor;

#[async_trait]
impl asynq::server::Handler for TaskProcessor {
  async fn process_task(&self, task: Task) -> Result<()> {
    match task.get_type() {
      "email:send" => {
        let payload: EmailPayload = serde_json::from_slice(task.get_payload())
          .map_err(|e| Error::other(format!("Failed to deserialize email:send payload: {}", e)))?;
        self.handle_email_send(payload).await
      }
      "email:reminder" => {
        let payload: EmailPayload = serde_json::from_slice(task.get_payload()).map_err(|e| {
          Error::other(format!(
            "Failed to deserialize email:reminder payload: {}",
            e
          ))
        })?;
        self.handle_email_reminder(payload).await
      }
      "image:resize" => {
        let payload: ImageResizePayload =
          serde_json::from_slice(task.get_payload()).map_err(|e| {
            Error::other(format!("Failed to deserialize image:resize payload: {}", e))
          })?;
        self.handle_image_resize(payload).await
      }
      "report:daily" => {
        let payload: serde_json::Value =
          serde_json::from_slice(task.get_payload()).map_err(|e| {
            Error::other(format!("Failed to deserialize report:daily payload: {}", e))
          })?;
        self.handle_daily_report(payload).await
      }
      "batch:process" => {
        let payload: serde_json::Value =
          serde_json::from_slice(task.get_payload()).map_err(|e| {
            Error::other(format!(
              "Failed to deserialize batch:process payload: {}",
              e
            ))
          })?;
        self.handle_batch_process(payload).await
      }
      "group:process" => {
        let payload: serde_json::Value =
          serde_json::from_slice(task.get_payload()).map_err(|e| {
            Error::other(format!(
              "Failed to deserialize group:process payload: {}",
              e
            ))
          })?;
        self.handle_group_process(payload).await
      }
      _ => {
        println!("âŒ Unknown task type: {}", task.get_type());
        Err(Error::other(format!(
          "Unknown task type: {}",
          task.get_type()
        )))
      }
    }
  }
}

impl TaskProcessor {
  async fn handle_email_send(&self, payload: EmailPayload) -> Result<()> {
    println!("ğŸ“§ Sending email to: {}", payload.to);
    println!("   Subject: {}", payload.subject);
    println!("   Body: {}", payload.body);

    // æ¨¡æ‹Ÿé‚®ä»¶å‘é€å¤„ç†
    tokio::time::sleep(Duration::from_secs(2)).await;

    println!("âœ… Email sent successfully to {}", payload.to);
    Ok(())
  }

  async fn handle_email_reminder(&self, payload: EmailPayload) -> Result<()> {
    println!("â° Sending reminder email to: {}", payload.to);
    println!("   Subject: {}", payload.subject);

    // æ¨¡æ‹Ÿæé†’é‚®ä»¶å¤„ç†
    tokio::time::sleep(Duration::from_secs(2)).await;

    println!("âœ… Reminder email sent to {}", payload.to);
    Ok(())
  }

  async fn handle_image_resize(&self, payload: ImageResizePayload) -> Result<()> {
    println!("ğŸ–¼ï¸  Resizing image: {}", payload.src_url);
    println!("   Target size: {}x{}", payload.width, payload.height);

    // æ¨¡æ‹Ÿå›¾ç‰‡å¤„ç†
    tokio::time::sleep(Duration::from_secs(3)).await;

    println!("âœ… Image resized successfully: {}", payload.src_url);
    Ok(())
  }

  async fn handle_daily_report(&self, payload: serde_json::Value) -> Result<()> {
    println!("ğŸ“Š Generating daily report for: {payload}");

    // æ¨¡æ‹ŸæŠ¥å‘Šç”Ÿæˆ
    tokio::time::sleep(Duration::from_secs(2)).await;

    println!("âœ… Daily report generated successfully");
    Ok(())
  }

  async fn handle_batch_process(&self, payload: serde_json::Value) -> Result<()> {
    println!("ğŸ”„ Processing batch item: {payload}");

    // æ¨¡æ‹Ÿæ‰¹å¤„ç†
    tokio::time::sleep(Duration::from_secs(1)).await;

    println!("âœ… Batch item processed: {payload}");
    Ok(())
  }

  async fn handle_group_process(&self, payload: serde_json::Value) -> Result<()> {
    println!("ğŸ”„ Processing group item: {payload}");

    // æ¨¡æ‹Ÿç»„ä»»åŠ¡å¤„ç†
    tokio::time::sleep(Duration::from_secs(1)).await;

    println!("âœ… Group item processed: {payload}");
    Ok(())
  }
}

#[tokio::main]
async fn main() -> std::result::Result<(), Box<dyn std::error::Error>> {
  tracing_subscriber::fmt::init();

  println!("ğŸš€ Starting Asynq worker with PostgresSQL...");

  // åˆ›å»º PostgresSQL é…ç½® - ä¼˜å…ˆä»ç¯å¢ƒå˜é‡ä¸­è¯»å–ï¼Œå¦åˆ™ä½¿ç”¨æœ¬åœ° PostgresSQL
  let database_url = std::env::var("DATABASE_URL")
    .unwrap_or_else(|_| "postgres://postgres:postgres@localhost:5432/asynq".to_string());
  println!("ğŸ”— Using PostgresSQL URL: {database_url}");

  // åˆ›å»º PostgresSQL ç»çºªäºº
  let broker = Arc::new(PostgresBroker::new(&database_url).await?);
  println!("âœ… Connected to PostgresSQL");

  // é…ç½®é˜Ÿåˆ—ä¼˜å…ˆçº§
  let mut queues = HashMap::new();
  queues.insert("critical".to_string(), 6); // æœ€é«˜ä¼˜å…ˆçº§
  queues.insert("default".to_string(), 3); // é»˜è®¤ä¼˜å…ˆçº§
  queues.insert("image_processing".to_string(), 2); // å›¾ç‰‡å¤„ç†é˜Ÿåˆ—
  queues.insert("low".to_string(), 1); // ä½ä¼˜å…ˆçº§

  // åˆ›å»ºæœåŠ¡å™¨é…ç½®
  let server_config = asynq::config::ServerConfig::new()
    .concurrency(4) // 4 ä¸ªå¹¶å‘å·¥ä½œè€…
    .queues(queues)
    .strict_priority(false) // ä¸ä½¿ç”¨ä¸¥æ ¼ä¼˜å…ˆçº§
    .enable_group_aggregator(true)
    .task_check_interval(Duration::from_secs(1))
    .shutdown_timeout(Duration::from_secs(10));

  // ä½¿ç”¨ ServerBuilder åˆ›å»ºæœåŠ¡å™¨
  // Use ServerBuilder to create server
  // postgres_broker() ä¼šè‡ªåŠ¨åˆ›å»º PostgresInspector ç”¨äºä»»åŠ¡ç›‘æ§
  // postgres_broker() automatically creates PostgresInspector for task monitoring
  let mut server = asynq::server::ServerBuilder::new()
    .postgres_broker(broker)
    .server_config(server_config)
    .build()
    .await?;
  // è®¾ç½®ç»„èšåˆå™¨
  // Set group aggregator
  println!("ğŸ“¦ Setting up group aggregator function...");
  let aggregator = GroupAggregatorFunc::new(aggregate_tasks);
  server.set_group_aggregator(aggregator);
  println!("   âœ… Group aggregator configured");
  // åˆ›å»ºä»»åŠ¡å¤„ç†å™¨
  let handler = TaskProcessor;

  // è¿è¡ŒæœåŠ¡å™¨
  println!("ğŸ”„ Server is running and waiting for tasks...");
  println!("Press Ctrl+C to gracefully shutdown");

  server.run(handler).await?;

  println!("ğŸ‘‹ Server shutdown complete");

  Ok(())
}
